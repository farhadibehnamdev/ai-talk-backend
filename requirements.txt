# ===========================================
# AI-Talk Backend Requirements
# ===========================================
# Hardware Requirements:
#   - NVIDIA GPU with 24GB+ VRAM (RTX 4090, A6000, etc.)
#   - CUDA 12.1+
#   - Python 3.11+
# ===========================================

# ===========================================
# FastAPI and Server
# ===========================================
fastapi==0.115.6
uvicorn[standard]==0.34.0
websockets==14.1
python-multipart==0.0.18

# ===========================================
# Environment and Configuration
# ===========================================
python-dotenv==1.0.1
pydantic>=2.10.0,<3.0.0
pydantic-settings>=2.7.0,<3.0.0

# ===========================================
# ML/AI Core Frameworks
# ===========================================
# PyTorch - Install with CUDA separately:
# pip install torch==2.5.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121
torch>=2.5.0,<3.0.0
torchaudio>=2.5.0,<3.0.0

# NumPy (compatible with torch 2.5.x)
numpy>=1.26.0,<2.0.0

# Transformers - Need >= 4.53.0 for native Kyutai STT support
# For now use latest stable, upgrade when 4.53.0 is released
transformers>=4.47.0
accelerate>=1.2.0

# ===========================================
# vLLM for Fast LLM Inference
# ===========================================
# Supports AWQ quantization for Qwen2.5-7B-Instruct-AWQ
# Install separately if issues: pip install vllm==0.6.6.post1
vllm>=0.6.6

# ===========================================
# Kyutai Moshi (STT + TTS)
# ===========================================
# Install from GitHub for latest version:
# pip install git+https://github.com/kyutai-labs/moshi.git
#
# Or install from PyPI:
moshi>=0.2.2

# Moshi dependencies
sentencepiece>=0.2.0
safetensors>=0.4.0

# ===========================================
# Hugging Face Hub (Model Downloads)
# ===========================================
huggingface-hub>=0.27.0

# ===========================================
# Audio Processing
# ===========================================
soundfile>=0.12.1
librosa>=0.10.2
scipy>=1.14.0

# Audio codec support
audioread>=3.0.0

# ===========================================
# Async Support
# ===========================================
aiofiles>=24.1.0
anyio>=4.7.0
aiohttp>=3.11.0

# ===========================================
# Redis for Session Management (Optional)
# ===========================================
redis>=5.2.0

# ===========================================
# Logging and Monitoring
# ===========================================
loguru>=0.7.3

# ===========================================
# HTTP Client
# ===========================================
httpx>=0.28.0

# ===========================================
# Development / Fallback TTS (Optional)
# ===========================================
# Uncomment if you want fallback TTS options:
# TTS>=0.22.0  # Coqui TTS
# edge-tts>=6.1.0  # Microsoft Edge TTS (online)

# ===========================================
# Testing (Optional)
# ===========================================
# pytest>=8.0.0
# pytest-asyncio>=0.24.0
# pytest-cov>=4.1.0

# ===========================================
# Code Quality (Optional)
# ===========================================
# black>=24.0.0
# isort>=5.13.0
# mypy>=1.8.0
# ruff>=0.1.0

# ===========================================
# Installation Notes
# ===========================================
# 1. First install PyTorch with CUDA:
#    pip install torch==2.5.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121
#
# 2. Then install vLLM:
#    pip install vllm==0.6.6.post1
#
# 3. Install Moshi from GitHub (recommended for latest):
#    pip install git+https://github.com/kyutai-labs/moshi.git
#
# 4. Finally install remaining requirements:
#    pip install -r requirements.txt
#
# ===========================================
# Model VRAM Requirements
# ===========================================
# kyutai/stt-2.6b-en:          ~6-8 GB
# kyutai/tts-1.6b-en_fr:       ~4-5 GB
# Qwen/Qwen2.5-7B-Instruct-AWQ: ~4-5 GB
# Total:                       ~16-20 GB
# Recommended GPU:             24GB+ (RTX 4090, A6000)
# ===========================================
