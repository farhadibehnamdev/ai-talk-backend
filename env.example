# ===========================================
# AI-Talk Backend Configuration
# ===========================================

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false
ENVIRONMENT=development

# ===========================================
# Model Configuration
# ===========================================

# LLM Model (Qwen2.5-7B-Instruct quantized)
LLM_MODEL_NAME=Qwen/Qwen2.5-7B-Instruct-AWQ
LLM_MAX_MODEL_LEN=4096
LLM_GPU_MEMORY_UTILIZATION=0.6

# ASR Model (Kyutai Moshi STT)
ASR_MODEL_NAME=kyutai/moshi-asr
ASR_SAMPLE_RATE=16000

# TTS Model (Kyutai Moshi TTS)
TTS_MODEL_NAME=kyutai/moshi-tts
TTS_SAMPLE_RATE=24000

# ===========================================
# Model Loading Options
# ===========================================

# Set to true to load models on startup (recommended for production)
# Set to false for faster startup during development
PRELOAD_MODELS=true

# Local path to store downloaded models
MODELS_CACHE_DIR=/app/models

# ===========================================
# WebSocket Configuration
# ===========================================

# Audio chunk size in milliseconds
AUDIO_CHUNK_MS=100

# Maximum conversation duration in seconds (0 = unlimited)
MAX_CONVERSATION_DURATION=1800

# WebSocket ping interval in seconds
WS_PING_INTERVAL=30

# ===========================================
# Redis Configuration (Optional)
# ===========================================

# Set to true to enable Redis for session management
REDIS_ENABLED=false
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# ===========================================
# CORS Configuration
# ===========================================

# Comma-separated list of allowed origins
CORS_ORIGINS=http://localhost:3000,https://your-frontend-domain.com

# ===========================================
# Logging
# ===========================================

LOG_LEVEL=INFO
